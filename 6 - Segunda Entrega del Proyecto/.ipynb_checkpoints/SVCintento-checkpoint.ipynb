{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b6bc787-7af2-437e-b0db-557d2cdd0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c1ce335-3987-479a-850a-e4b197afff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_dataset = pd.read_csv(\"stroke.csv\")\n",
    "stroke_dataset = stroke_dataset.drop(\"id\", axis=1)\n",
    "imputador = KNNImputer(n_neighbors=3, weights=\"uniform\")\n",
    "stroke_dataset['imputed_bmi'] = imputador.fit_transform(stroke_dataset[['bmi']])\n",
    "stroke_dataset.isna().sum()\n",
    "stroke_dataset = stroke_dataset.drop(\"bmi\", axis = 1)\n",
    "stroke_dataset = stroke_dataset.rename(columns={'imputed_bmi': 'bmi'})\n",
    "stroke_dataset = stroke_dataset.drop(3116)\n",
    "# Eliminamos un individuo del dataset que no especifico su sexo\n",
    "stroke_dataset.to_csv(\"stroke_imputed.csv\", index=False)\n",
    "stroke_dataset = pd.read_csv(\"stroke_imputed.csv\")\n",
    "stroke_dataset.stroke = stroke_dataset.stroke.replace({'Non-Stroke':0,'Stroke':1})\n",
    "stroke_dataset.heart_disease = stroke_dataset.heart_disease.replace({'No':0,'Yes':1})\n",
    "stroke_dataset.hypertension = stroke_dataset.hypertension.replace({'No':0,'Yes':1})\n",
    "stroke_dataset[\"gender\"].replace({\"Male\": 1, \"Female\": 0}, inplace=True)\n",
    "stroke_dataset[\"Residence_type\"].replace({\"Rural\": 0, \"Urban\": 1}, inplace=True)\n",
    "stroke_dataset[\"ever_married\"].replace({\"Yes\": 1, \"No\": 0}, inplace=True)\n",
    "\n",
    "stroke_dataset = pd.get_dummies(stroke_dataset, columns=['smoking_status'])\n",
    "stroke_dataset = stroke_dataset.drop(\"smoking_status_Unknown\", axis = 1)\n",
    "stroke_dataset = pd.get_dummies(stroke_dataset, columns=['work_type'])\n",
    "stroke_dataset = stroke_dataset.drop(\"work_type_Never_worked\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995333c9-4ec2-42f3-b883-c64ca0a9c8ad",
   "metadata": {},
   "source": [
    "### SVC (Support Vector Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c59d008-3d55-4bad-9a13-1a16a8f3a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = stroke_dataset.drop([\"stroke\"], axis=1)\n",
    "Y4 = stroke_dataset[\"stroke\"]\n",
    "\n",
    "X4_train, X4_test, Y4_train, Y4_test = train_test_split(\n",
    "                                        X4,\n",
    "                                        Y4.values.reshape(-1,1),\n",
    "                                        train_size   = 0.7,\n",
    "                                        random_state = 11,\n",
    "                                        shuffle      = True\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108a466a-9f35-4ac1-8cce-cd32bedcd348",
   "metadata": {},
   "source": [
    "Creamos el modelo SVM (support vector machine). Un support vector machine construye un hyper-plano, o una serie de hyper-planos en n dimensiones, que podemos utilizar para nuestro analisis de clasificacion. La matematica del modelo determina el mejor conjunto de vectores los cuales maximizan el margen entre los vectores (es decir maximizan la distancia entre los inputs y sus subclases) sin incurrir en misclasificar dicho sample, es decir sin adjudicar ese input en una subclase no optima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f04c81e-2276-4410-a2d7-edd1472d38b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, kernel='linear', random_state=11)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = SVC(C = 100, kernel = 'linear', random_state=11)\n",
    "model4.fit(X4_train, Y4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ed0483a-6264-42d2-a0fb-69e96f5553cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y4_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d9f3d1e-2380-4a58-a50e-2854607a4436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3576"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X4_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5c7fc65-11f8-4f9a-aa69-8ee2cb0e3c19",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1533, 3576]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m Y4_test_pred \u001b[38;5;241m=\u001b[39m model4\u001b[38;5;241m.\u001b[39mpredict(X4_train)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#test4_accuracy = accuracy_score(Y4_test, Y4_test_pred)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Accuracy\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy the classifier is : \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY4_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY4_test_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true)\n\u001b[0;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    335\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1533, 3576]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Y4_test_pred = model4.predict(X4_train)\n",
    "#test4_accuracy = accuracy_score(Y4_test, Y4_test_pred)\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy the classifier is : {:.2f}%\".format(accuracy_score(Y4_test, Y4_test_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d97a98-062c-466e-a9cb-e0651313691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matriz de Confusi√≥n\n",
    "print(confusion_matrix(Y4_test, Y4_test_pred))\n",
    "\n",
    "#Ploteamos la Matriz\n",
    "plot_confusion_matrix(model4, X4_test, Y4_test, normalize = None, cmap = 'Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ced60b3-c133-41a6-907f-b340f64706a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
